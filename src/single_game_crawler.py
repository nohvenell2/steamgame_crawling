import asyncio
import aiohttp
from bs4 import BeautifulSoup
from typing import Dict, List, Optional, Any
import re
from datetime import datetime
import json
import csv
import os
from pathlib import Path

class ComprehensiveGameCrawler:
    def __init__(self):
        self.base_url = "https://store.steampowered.com/app/"
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

    def get_age_verification_cookies(self):
        """ë‚˜ì´ ì¸ì¦ì„ ìš°íšŒí•˜ê¸° ìœ„í•œ ì¿ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            'birthtime': '1',
            'mature_content': '1',
            'lastagecheckage': '1-January-1970'
        }

    async def handle_age_check(self, session: aiohttp.ClientSession, url: str) -> Optional[str]:
        """ë‚˜ì´ ì¸ì¦ í˜ì´ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            async with session.get(url, headers=self.headers) as response:
                if response.status == 200:
                    html = await response.text()
                    
                    if 'agecheck' in html or 'agegate' in html:
                        print("ë‚˜ì´ ì¸ì¦ í˜ì´ì§€ ê°ì§€, ìš°íšŒ ì¤‘...")
                        form_data = {
                            'snr': '1_agecheck_agecheck__age-gate',
                            'ageDay': '1',
                            'ageMonth': 'January', 
                            'ageYear': '1990'
                        }
                        
                        async with session.post(url, data=form_data, headers=self.headers) as post_response:
                            if post_response.status == 200:
                                return await post_response.text()
                    
                    return html
        except Exception as e:
            print(f"ë‚˜ì´ ì¸ì¦ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def extract_basic_info(self, soup: BeautifulSoup, app_id: int) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²Œì„ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        info = {}
        
        # ê²Œì„ ì œëª©
        title_selectors = [
            'div.apphub_AppName',
            'h1.pageheader',
            '.game_title h1',
            '#appHubAppName'
        ]
        
        for selector in title_selectors:
            element = soup.select_one(selector)
            if element:
                info['title'] = element.get_text(strip=True)
                break
        
        if 'title' not in info:
            info['title'] = "Unknown"
        
        # ê²Œì„ ì„¤ëª…
        desc_selectors = [
            '.game_description_snippet',
            '.game_area_description .game_description_snippet'
        ]
        
        for selector in desc_selectors:
            element = soup.select_one(selector)
            if element:
                info['description'] = element.get_text(strip=True)
                break
        
        if 'description' not in info:
            info['description'] = ""
        
        return info

    def extract_tags(self, soup: BeautifulSoup) -> List[str]:
        """ê²Œì„ íƒœê·¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        tags = []
        tag_selectors = [
            'a.app_tag',
            '.popular_tags a',
            '.game_area_details_specs a'
        ]
        
        for selector in tag_selectors:
            tag_elements = soup.select(selector)
            if tag_elements:
                for tag in tag_elements:
                    tag_text = tag.get_text(strip=True)
                    if tag_text and tag_text not in tags:
                        tags.append(tag_text)
                break
        
        return tags

    def extract_price_info(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """ê°€ê²© ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        price_info = {
            'current_price': None,
            'original_price': None,
            'discount_percent': None,
            'is_free': False
        }
        
        # ë¬´ë£Œ ê²Œì„ í™•ì¸
        free_elements = soup.select('.game_purchase_price')
        for elem in free_elements:
            text = elem.get_text(strip=True).lower()
            if 'free' in text or 'ë¬´ë£Œ' in text:
                price_info['is_free'] = True
                price_info['current_price'] = "Free"
                return price_info
        
        # í˜„ì¬ ê°€ê²©
        current_price_selectors = [
            '.game_purchase_price',
            '.discount_final_price'
        ]
        
        for selector in current_price_selectors:
            element = soup.select_one(selector)
            if element:
                price_text = element.get_text(strip=True)
                if price_text and price_text != '--':
                    price_info['current_price'] = price_text
                    break
        
        # ì›ë˜ ê°€ê²© (í• ì¸ ì‹œ)
        original_price_element = soup.select_one('.discount_original_price')
        if original_price_element:
            price_info['original_price'] = original_price_element.get_text(strip=True)
        
        # í• ì¸ìœ¨
        discount_element = soup.select_one('.discount_pct')
        if discount_element:
            discount_text = discount_element.get_text(strip=True)
            # "-50%" í˜•íƒœì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
            discount_match = re.search(r'-(\d+)%', discount_text)
            if discount_match:
                price_info['discount_percent'] = int(discount_match.group(1))
        
        return price_info

    def extract_developer_publisher(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """ê°œë°œì‚¬/í¼ë¸”ë¦¬ì…” ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        dev_pub_info: Dict[str, Any] = {
            'developer': None,
            'publisher': None
        }
        
        # ê°œë°œì‚¬/í¼ë¸”ë¦¬ì…” ì •ë³´ ì¶”ì¶œ - ë‹¤ì–‘í•œ ë°©ë²• ì‹œë„
        try:
            # ë°©ë²• 1: ê²Œì„ ìƒì„¸ ì •ë³´ì—ì„œ ì°¾ê¸°
            details_specs = soup.select('.game_area_details_specs .summary')
            
            for i, spec in enumerate(details_specs):
                text = spec.get_text(strip=True).lower()
                
                # ë‹¤ìŒ ìš”ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸
                if i + 1 < len(details_specs):
                    next_spec = details_specs[i + 1]
                    value = next_spec.get_text(strip=True)
                    
                    if 'developer' in text:
                        dev_pub_info['developer'] = value
                    elif 'publisher' in text:
                        dev_pub_info['publisher'] = value
            
            # ë°©ë²• 2: dev_row í´ë˜ìŠ¤ë¡œ ì°¾ê¸°
            if not dev_pub_info['developer'] or not dev_pub_info['publisher']:
                dev_rows = soup.select('.dev_row')
                for row in dev_rows:
                    summary = row.select_one('.summary')
                    if summary:
                        summary_text = summary.get_text(strip=True).lower()
                        if 'developer' in summary_text:
                            dev_link = row.select_one('a')
                            if dev_link:
                                dev_pub_info['developer'] = dev_link.get_text(strip=True)
                        elif 'publisher' in summary_text:
                            pub_link = row.select_one('a')
                            if pub_link:
                                dev_pub_info['publisher'] = pub_link.get_text(strip=True)
            
            # ë°©ë²• 3: ë§í¬ href ì†ì„±ìœ¼ë¡œ ì°¾ê¸°
            if not dev_pub_info['developer']:
                dev_elements = soup.select('a[href*="developer"]')
                if dev_elements:
                    dev_pub_info['developer'] = dev_elements[0].get_text(strip=True)
            
            if not dev_pub_info['publisher']:
                pub_elements = soup.select('a[href*="publisher"]')
                if pub_elements:
                    dev_pub_info['publisher'] = pub_elements[0].get_text(strip=True)
            
            # ë°©ë²• 4: ê²Œì„ ì •ë³´ ë¸”ë¡ì—ì„œ ì§ì ‘ ì°¾ê¸°
            if not dev_pub_info['developer'] or not dev_pub_info['publisher']:
                # ëª¨ë“  í…ìŠ¤íŠ¸ì—ì„œ "Developer:" ë˜ëŠ” "Publisher:" íŒ¨í„´ ì°¾ê¸°
                all_text = soup.get_text()
                
                # Developer íŒ¨í„´ ì°¾ê¸°
                dev_match = re.search(r'Developer[:\s]+([^\n\r]+)', all_text, re.IGNORECASE)
                if dev_match and not dev_pub_info['developer']:
                    dev_pub_info['developer'] = dev_match.group(1).strip()
                
                # Publisher íŒ¨í„´ ì°¾ê¸°
                pub_match = re.search(r'Publisher[:\s]+([^\n\r]+)', all_text, re.IGNORECASE)
                if pub_match and not dev_pub_info['publisher']:
                    dev_pub_info['publisher'] = pub_match.group(1).strip()
            
            # ë°©ë²• 5: íŠ¹ì • í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ì°¾ê¸°
            if not dev_pub_info['developer'] or not dev_pub_info['publisher']:
                # ë‹¤ë¥¸ ê°€ëŠ¥í•œ ì„ íƒìë“¤
                possible_selectors = [
                    '.glance_ctn .summary',
                    '.details_block .summary',
                    '.game_area_details .summary'
                ]
                
                for selector in possible_selectors:
                    elements = soup.select(selector)
                    for i, elem in enumerate(elements):
                        text = elem.get_text(strip=True).lower()
                        if 'developer' in text and i + 1 < len(elements):
                            if not dev_pub_info['developer']:
                                dev_pub_info['developer'] = elements[i + 1].get_text(strip=True)
                        elif 'publisher' in text and i + 1 < len(elements):
                            if not dev_pub_info['publisher']:
                                dev_pub_info['publisher'] = elements[i + 1].get_text(strip=True)
                    
                    if dev_pub_info['developer'] and dev_pub_info['publisher']:
                        break
                        
        except Exception as e:
            print(f"ê°œë°œì‚¬/í¼ë¸”ë¦¬ì…” ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return dev_pub_info

    def extract_release_date(self, soup: BeautifulSoup) -> Optional[str]:
        """ì¶œì‹œì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        release_selectors = [
            '.release_date .date',
            '.game_area_release_date .date'
        ]
        
        for selector in release_selectors:
            element = soup.select_one(selector)
            if element:
                return element.get_text(strip=True)
        
        return None

    def extract_review_info(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """ë¦¬ë·°/í‰ì  ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        review_info: Dict[str, Any] = {
            'recent_reviews': None,
            'all_reviews': None,
            'recent_review_count': None,
            'total_review_count': None,
            'recent_positive_percent': None,
            'total_positive_percent': None
        }
        
        # ë¦¬ë·° ìš”ì•½ ì •ë³´
        review_summaries = soup.select('.game_review_summary')
        if len(review_summaries) >= 2:
            review_info['recent_reviews'] = review_summaries[0].get_text(strip=True)
            review_info['all_reviews'] = review_summaries[1].get_text(strip=True)
        elif len(review_summaries) == 1:
            review_info['all_reviews'] = review_summaries[0].get_text(strip=True)
        
        # ìƒì„¸ ë¦¬ë·° í†µê³„ - ë” ì •í™•í•œ ì¶”ì¶œ
        try:
            # ë¦¬ë·° í†µê³„ ì •ë³´ê°€ ìˆëŠ” ì„¹ì…˜ ì°¾ê¸°
            review_sections = soup.select('.user_reviews_summary_row')
            
            for section in review_sections:
                section_text = section.get_text()
                
                # ìµœê·¼ ë¦¬ë·° ì„¹ì…˜
                if 'Recent Reviews' in section_text or 'ìµœê·¼ ë¦¬ë·°' in section_text:
                    # ê´„í˜¸ ì•ˆì˜ ìˆ«ì ì¶”ì¶œ (ë¦¬ë·° ê°œìˆ˜)
                    count_match = re.search(r'\((\d{1,3}(?:,\d{3})*)\)', section_text)
                    if count_match:
                        review_info['recent_review_count'] = count_match.group(1)
                    
                    # í¼ì„¼íŠ¸ ì¶”ì¶œ - ë” ì •í™•í•œ íŒ¨í„´
                    percent_match = re.search(r'(\d+)%\s+of\s+the\s+\d+', section_text)
                    if percent_match:
                        review_info['recent_positive_percent'] = int(percent_match.group(1))
                
                # ì „ì²´ ë¦¬ë·° ì„¹ì…˜
                elif 'All Reviews' in section_text or 'ëª¨ë“  ë¦¬ë·°' in section_text:
                    # ê´„í˜¸ ì•ˆì˜ ìˆ«ì ì¶”ì¶œ (ë¦¬ë·° ê°œìˆ˜)
                    count_match = re.search(r'\((\d{1,3}(?:,\d{3})*)\)', section_text)
                    if count_match:
                        review_info['total_review_count'] = count_match.group(1)
                    
                    # í¼ì„¼íŠ¸ ì¶”ì¶œ - ë” ì •í™•í•œ íŒ¨í„´
                    percent_match = re.search(r'(\d+)%\s+of\s+the\s+\d+', section_text)
                    if percent_match:
                        review_info['total_positive_percent'] = int(percent_match.group(1))
            
            # ì¶”ê°€ ì‹œë„: ë‹¤ë¥¸ ì„ íƒìë¡œ ë¦¬ë·° í†µê³„ ì°¾ê¸°
            if not review_info['total_review_count']:
                # ë¦¬ë·° í†µê³„ë¥¼ ë‹´ê³  ìˆëŠ” ë‹¤ë¥¸ ìš”ì†Œë“¤ ì‹œë„
                review_stats = soup.select('.responsive_reviewdesc')
                for stat in review_stats:
                    stat_text = stat.get_text()
                    
                    # "94% of the 123,456 user reviews" íŒ¨í„´ ì°¾ê¸°
                    match = re.search(r'(\d+)%\s+of\s+the\s+([\d,]+)\s+user\s+reviews', stat_text)
                    if match:
                        review_info['total_positive_percent'] = int(match.group(1))
                        review_info['total_review_count'] = match.group(2)
                        break
                        
        except Exception as e:
            print(f"ë¦¬ë·° ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return review_info

    def extract_header_images(self, soup: BeautifulSoup, app_id: int) -> List[str]:
        """í—¤ë” ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        header_images = []
        
        # HTMLì—ì„œ í—¤ë” ì´ë¯¸ì§€ ì°¾ê¸°
        header_selectors = [
            '.game_header_image_full',
            '.game_header_image img',
            '.page_header_image img'
        ]
        
        for selector in header_selectors:
            elements = soup.select(selector)
            for elem in elements:
                src = elem.get('src', '')
                if src and src not in header_images:
                    header_images.append(src)
        
        # Steamì˜ í‘œì¤€ í—¤ë” ì´ë¯¸ì§€ URL íŒ¨í„´ ì¶”ê°€
        standard_header_url = f"https://shared.fastly.steamstatic.com/store_item_assets/steam/apps/{app_id}/header.jpg"
        if standard_header_url not in header_images:
            header_images.append(standard_header_url)
        
        return header_images

    def extract_system_requirements(self, soup: BeautifulSoup) -> Dict[str, str]:
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        sys_req = {
            'minimum': '',
            'recommended': ''
        }
        
        sys_req_sections = soup.select('.game_area_sys_req')
        for section in sys_req_sections:
            text = section.get_text()
            if 'Minimum' in text or 'ìµœì†Œ' in text:
                sys_req['minimum'] = text.strip()
            elif 'Recommended' in text or 'ê¶Œì¥' in text:
                sys_req['recommended'] = text.strip()
        
        return sys_req

    async def get_comprehensive_game_info(self, app_id: int) -> Dict[str, Any]:
        """ê²Œì„ IDë¥¼ ì…ë ¥ë°›ì•„ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        url = f"{self.base_url}{app_id}"
        print(f"ì¢…í•© ì •ë³´ ì¶”ì¶œ ì¤‘: {url}")
        
        try:
            jar = aiohttp.CookieJar(unsafe=True)
            async with aiohttp.ClientSession(cookie_jar=jar) as session:
                cookies = self.get_age_verification_cookies()
                
                async with session.get(url, headers=self.headers, cookies=cookies) as response:
                    if response.status == 200:
                        html = await response.text()
                        
                        # ë‚˜ì´ ì¸ì¦ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ëœ ê²½ìš° ì²˜ë¦¬
                        if 'agecheck' in response.url.path or 'agegate' in html.lower():
                            html = await self.handle_age_check(session, str(response.url))
                            if not html:
                                return {}
                        
                        soup = BeautifulSoup(html, 'html.parser')
                        
                        # ëª¨ë“  ì •ë³´ ì¶”ì¶œ
                        game_info = {
                            'app_id': app_id,
                            'crawled_at': datetime.now().isoformat(),
                            **self.extract_basic_info(soup, app_id),
                            'tags': self.extract_tags(soup),
                            'price_info': self.extract_price_info(soup),
                            'developer_publisher': self.extract_developer_publisher(soup),
                            'release_date': self.extract_release_date(soup),
                            'review_info': self.extract_review_info(soup),
                            'header_images': self.extract_header_images(soup, app_id),
                            'system_requirements': self.extract_system_requirements(soup)
                        }
                        
                        return game_info
                    else:
                        print(f"HTTP ì˜¤ë¥˜: {response.status}")
                        return {}
                        
        except Exception as e:
            print(f"ì¢…í•© ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}


# í¸ì˜ í•¨ìˆ˜ë“¤
async def get_steam_game_info(app_id: int) -> Dict[str, Any]:
    """
    Steam ê²Œì„ IDë¥¼ ì…ë ¥ë°›ì•„ ëª¨ë“  ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
    
    Args:
        app_id (int): Steam ê²Œì„ ID
        
    Returns:
        Dict[str, Any]: ê²Œì„ì˜ ëª¨ë“  ì •ë³´
        
    Example:
        info = await get_steam_game_info(1091500)  # Cyberpunk 2077
        print(f"ì œëª©: {info['title']}")
        print(f"ê°€ê²©: {info['price_info']['current_price']}")
        print(f"íƒœê·¸: {info['tags']}")
    """
    crawler = ComprehensiveGameCrawler()
    return await crawler.get_comprehensive_game_info(app_id)


def get_steam_game_info_sync(app_id: int) -> Dict[str, Any]:
    """
    Steam ê²Œì„ IDë¥¼ ì…ë ¥ë°›ì•„ ëª¨ë“  ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” ë™ê¸° í•¨ìˆ˜
    
    Args:
        app_id (int): Steam ê²Œì„ ID
        
    Returns:
        Dict[str, Any]: ê²Œì„ì˜ ëª¨ë“  ì •ë³´
        
    Example:
        info = get_steam_game_info_sync(1091500)  # Cyberpunk 2077
        print(f"ì œëª©: {info['title']}")
        print(f"ê°€ê²©: {info['price_info']['current_price']}")
        print(f"íƒœê·¸: {info['tags']}")
    """
    return asyncio.run(get_steam_game_info(app_id))


def save_game_info_json(game_info: Dict[str, Any], filename: Optional[str] = None) -> str:
    """ê²Œì„ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    if not game_info:
        raise ValueError("ì €ì¥í•  ê²Œì„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # íŒŒì¼ëª… ìƒì„±
    if not filename:
        app_id = game_info.get('app_id', 'unknown')
        title = game_info.get('title', 'unknown').replace('/', '_').replace('\\', '_')
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        safe_title = re.sub(r'[<>:"|?*]', '', title)[:50]
        filename = f"game_{app_id}_{safe_title}.json"
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_dir = Path("data/game_info")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # íŒŒì¼ ê²½ë¡œ
    file_path = save_dir / filename
    
    # JSONìœ¼ë¡œ ì €ì¥
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(game_info, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ê²Œì„ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {file_path}")
    return str(file_path)


def save_multiple_games_csv(games_info: List[Dict[str, Any]], filename: Optional[str] = None) -> str:
    """ì—¬ëŸ¬ ê²Œì„ ì •ë³´ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    if not games_info:
        raise ValueError("ì €ì¥í•  ê²Œì„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # íŒŒì¼ëª… ìƒì„±
    if not filename:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"games_info_{timestamp}.csv"
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_dir = Path("data/game_info")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # íŒŒì¼ ê²½ë¡œ
    file_path = save_dir / filename
    
    # CSV í—¤ë” ì •ì˜
    headers = [
        'app_id', 'title', 'description', 'current_price', 'original_price', 
        'discount_percent', 'is_free', 'developer', 'publisher', 'release_date',
        'all_reviews', 'total_review_count', 'total_positive_percent',
        'tags', 'header_image', 'crawled_at'
    ]
    
    # CSVë¡œ ì €ì¥
    with open(file_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        
        for game_info in games_info:
            # ë°ì´í„° í‰íƒ„í™”
            row = {
                'app_id': game_info.get('app_id', ''),
                'title': game_info.get('title', ''),
                'description': game_info.get('description', '')[:200] + '...' if len(game_info.get('description', '')) > 200 else game_info.get('description', ''),
                'current_price': game_info.get('price_info', {}).get('current_price', ''),
                'original_price': game_info.get('price_info', {}).get('original_price', ''),
                'discount_percent': game_info.get('price_info', {}).get('discount_percent', ''),
                'is_free': game_info.get('price_info', {}).get('is_free', False),
                'developer': game_info.get('developer_publisher', {}).get('developer', ''),
                'publisher': game_info.get('developer_publisher', {}).get('publisher', ''),
                'release_date': game_info.get('release_date', ''),
                'all_reviews': game_info.get('review_info', {}).get('all_reviews', ''),
                'total_review_count': game_info.get('review_info', {}).get('total_review_count', ''),
                'total_positive_percent': game_info.get('review_info', {}).get('total_positive_percent', ''),
                'tags': ', '.join(game_info.get('tags', [])),
                'header_image': game_info.get('header_images', [''])[0] if game_info.get('header_images') else '',
                'crawled_at': game_info.get('crawled_at', '')
            }
            writer.writerow(row)
    
    print(f"âœ… {len(games_info)}ê°œ ê²Œì„ ì •ë³´ê°€ CSVë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {file_path}")
    return str(file_path)


def load_game_info_json(file_path: str) -> Dict[str, Any]:
    """JSON íŒŒì¼ì—ì„œ ê²Œì„ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def print_game_info(game_info: Dict[str, Any]):
    """ê²Œì„ ì •ë³´ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    if not game_info:
        print("ê²Œì„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\n=== {game_info.get('title', 'Unknown')} (ID: {game_info.get('app_id')}) ===")
    print(f"ğŸ“ ì„¤ëª…: {game_info.get('description', 'N/A')[:100]}...")
    print(f"ğŸ’° ê°€ê²©: {game_info.get('price_info', {}).get('current_price', 'N/A')}")
    print(f"ğŸ‘¨â€ğŸ’» ê°œë°œì‚¬: {game_info.get('developer_publisher', {}).get('developer', 'N/A')}")
    print(f"ğŸ¢ í¼ë¸”ë¦¬ì…”: {game_info.get('developer_publisher', {}).get('publisher', 'N/A')}")
    print(f"ğŸ“… ì¶œì‹œì¼: {game_info.get('release_date', 'N/A')}")
    print(f"â­ ì „ì²´ ë¦¬ë·°: {game_info.get('review_info', {}).get('all_reviews', 'N/A')}")
    print(f"ğŸ·ï¸ íƒœê·¸: {', '.join(game_info.get('tags', [])[:5])}...")
    print(f"ğŸ–¼ï¸ í—¤ë” ì´ë¯¸ì§€: {game_info.get('header_images', ['N/A'])[0]}")


async def main():
    # í…ŒìŠ¤íŠ¸
    test_games = [
        #(1091500, "Cyberpunk 2077"),
        #(570, "Dota 2"),
        #(730, "Counter-Strike 2")
        (1284790,'unable')

    ]
    
    all_games_info = []
    
    for app_id, expected_title in test_games:
        print(f"\n{'='*50}")
        print(f"í…ŒìŠ¤íŠ¸ ì¤‘: {expected_title} (ID: {app_id})")
        print(f"{'='*50}")
        
        game_info = await get_steam_game_info(app_id)
        print_game_info(game_info)
        
        if game_info:
            # ê°œë³„ ê²Œì„ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì €ì¥
            save_game_info_json(game_info)
            all_games_info.append(game_info)
    
    # ëª¨ë“  ê²Œì„ ì •ë³´ë¥¼ CSVë¡œ ì €ì¥
    if all_games_info:
        save_multiple_games_csv(all_games_info, "test_games.csv")
        
        print(f"\nğŸ“Š ì´ {len(all_games_info)}ê°œ ê²Œì„ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!")
        print("ğŸ’¾ ê°œë³„ JSON íŒŒì¼ê³¼ í†µí•© CSV íŒŒì¼ì´ data/game_info/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main()) 